{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c55e31-8223-481a-9dfb-a1d9c27ce5ef",
   "metadata": {},
   "source": [
    "# LSTM implementation in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81004501-bc34-414b-9df4-6cd07c633174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3056144-dbba-45ee-a57c-6b7de97f9fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, cell_state_width, hidden_width, input_width):\n",
    "        \n",
    "        self.cell_state_width = cell_state_width\n",
    "        self.hidden_width = hidden_width\n",
    "        self.input_width = input_width\n",
    "        \n",
    "        self.W_forget = nn.Linear(in_features=input_width+hidden_width,\n",
    "                                 out_features=cell_state_width)\n",
    "        \n",
    "        self.W_i_update = nn.Linear(in_features=input_width+hidden_width,\n",
    "                                    out_features=cell_state_width)\n",
    "        \n",
    "        self.W_i_update_values = nn.Linear(in_features=input_width+hidden_width,\n",
    "                                           out_features=cell_state_width)\n",
    "        \n",
    "        self.W_CS_to_output = nn.Linear(in_features=cell_state_width,\n",
    "                                        out_features=hidden_width)\n",
    "        \n",
    "        self.W_combined_to_output = nn.Linear(in_features=input_width+hidden_width,\n",
    "                                              out_features=hidden_width)\n",
    "        \n",
    "    def forward(self, X, cell_state=None, hidden_state=None):\n",
    "        if cell_state is None:\n",
    "            cell_state = self.get_blank_cell_state()\n",
    "        if hidden_state is None:\n",
    "            hidden_state = self.get_blank_hidden_state()\n",
    "        \n",
    "        combined_state = torch.concat(X, hidden_state)\n",
    "        \n",
    "        forget_factor = torch.sigmoid(self.W_forget(combined_state))\n",
    "        new_cell_state = cell_state * forget_factor\n",
    "        \n",
    "        creation_gate_gating = torch.sigmoid(self.W_i_update(combined_state))\n",
    "        creation_gate_values = torch.tanh(self.W_i_update_values(combined_state))\n",
    "        \n",
    "        new_cell_state += creation_gate_gating * creation_gate_values\n",
    "        \n",
    "        cell_state_output_contrib = torch.tanh(self.W_CS_to_output(new_cell_state))\n",
    "        combined_state_output_contrib = torch.sigmoid(self.W_combined_to_output(combined_state))\n",
    "        \n",
    "        new_hidden_state = cell_state_output_contrib * combined_state_output_contrib\n",
    "        \n",
    "        return new_hidden_state, new_cell_state\n",
    "        \n",
    "    def get_blank_hidden_state(self, batchsize=1):\n",
    "        return torch.zeros(batchsize, self.hidden_width)\n",
    "    \n",
    "    def get_blank_cell_state(self, batchsize=1):\n",
    "        return torch.zeros(batchsize, self.cell_state_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d29cc60-3a71-487f-8084-a7ac8002ae1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffcfba91-1ee1-48a2-930c-90a032f693d4",
   "metadata": {},
   "source": [
    "Source(s):\n",
    "- https://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c7a3a-2279-4e1b-a640-78b61981a572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
