{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26872fbb-74b1-4854-89f3-74ecffc92cbb",
   "metadata": {},
   "source": [
    "Todo:\n",
    "- Add training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "255a26e2-431d-4d6b-9f7a-d7cf1a584669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b062cea5-dabe-4d14-ad57-959510a53232",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_inputs, n_hiddens, n_outputs):\n",
    "        super().__init__()\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_hiddens = n_hiddens\n",
    "        self.n_outputs = n_outputs\n",
    "        \n",
    "        self.input_to_hidden = nn.Linear(n_inputs, n_hiddens, bias=False)\n",
    "        self.hidden_to_hidden = nn.Linear(n_hiddens, n_hiddens)\n",
    "        self.hidden_to_output = nn.Linear(n_hiddens, n_outputs)\n",
    "    \n",
    "    def forward(self, X, hidden_state):\n",
    "        X = self.input_to_hidden(X)\n",
    "        hidden_state = self.hidden_to_hidden(hidden_state)\n",
    "        hidden_state = torch.tanh(X + hidden_state)\n",
    "        output = self.hidden_to_output(hidden_state)\n",
    "        \n",
    "        return output, hidden_state\n",
    "    \n",
    "    def init_zero_hidden(self, batch_size=1):\n",
    "        return torch.zeros(batch_size, self.n_hiddens, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "413efba0-2321-497e-90cb-5413ea4060c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: RNN, \n",
    "          dataloader: DataLoader, \n",
    "          epochs: int, \n",
    "          optimizer: optim.Optimizer, \n",
    "          loss_fn: nn.Module,\n",
    "          batch_size: int):\n",
    "    train_losses = {}\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_losses = []\n",
    "        for X, y in dataloader:\n",
    "            \n",
    "            hidden = model.init_zero_hidden(batch_size=batch_size)\n",
    "            model.zero_grad()\n",
    "            loss = 0\n",
    "            \n",
    "            for token_index in range(X.shape[0]):\n",
    "                output, hidden = model(token, hidden)\n",
    "                loss += loss_fn(output, y[token_index])\n",
    "                \n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=3)\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "55d76e00-c4a6-4df6-851c-b63144da49a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_words = [\"yo what's up homie\", 'how are you doing man', 'i enjoy listening to beethoven']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1c43b662-5390-42dc-ac7a-515fe979d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set(''.join(training_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "61e2d1c7-16b3-4a17-af3d-d221b71ad877",
   "metadata": {},
   "outputs": [],
   "source": [
    "int2char = dict(enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e96db48d-7df3-4c5f-9e9c-7d0692ea1ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2int = {character : value for value, character in int2char.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "58e52c07-6920-49c4-b365-fdb7753a61e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = len(max(training_words, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "982ecdde-937d-46fd-9cfb-90bd8048132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(training_words)):\n",
    "    for _ in range(maxlen - len(training_words[i])):\n",
    "        training_words[i] += ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "294a8632-0187-4460-9044-481c1fea635e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"yo what's up homie            \",\n",
       " 'how are you doing man         ',\n",
       " 'i enjoy listening to beethoven']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c68c92a1-c2dc-4116-8208-8ee5035fd906",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "target_sequences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "695ef2f8-e2ef-48ad-a9d6-a2a48cc32ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(training_words)):\n",
    "    input_sequences.append(training_words[i][:-1])\n",
    "    target_sequences.append(training_words[i][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "20fb7bfd-963e-49ea-a15e-ba9b8dc6baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(training_words)):\n",
    "    input_sequences[i] = [char2int[character] for character in input_sequences[i]]\n",
    "    target_sequences[i] = [char2int[character] for character in target_sequences[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "61793e7e-137c-4321-b0f3-4fa706eea264",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_size = len(char2int)\n",
    "sequence_length = maxlen - 1\n",
    "batch_size = len(training_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "45d15513-7074-42c6-98eb-739231730ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(sequences, dict_size, seq_len, batch_size):\n",
    "    features = np.zeros(shape=(batch_size, seq_len, dict_size), dtype=np.float32)\n",
    "    \n",
    "    for i in range(len(sequences)):\n",
    "        for token_index in range(len(sequences[i])):\n",
    "            #print(i, token_index, sequences[i][token_index])\n",
    "            features[i, token_index, sequences[i][token_index]] = 1\n",
    "            \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "957d75cf-463a-43b3-a2ee-658916e7e228",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences_onehot = one_hot_encode(input_sequences, dict_size, sequence_length, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "736dd36c-b00d-4f99-bec4-c1d7fa583220",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences_onehot = torch.from_numpy(input_sequences_onehot)\n",
    "target_sequences = torch.Tensor(target_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0824cb6c-307f-4cad-8c0c-9f59c983134a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 1., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "eeae6283-bc48-4a29-91ad-823159ffc0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0429,  0.2822,  0.3401,  ...,  0.1586, -0.0085,  0.4177],\n",
       "          [-0.0966,  0.1920,  0.3414,  ..., -0.0144,  0.0038,  0.3242],\n",
       "          [-0.0758,  0.2001,  0.1977,  ...,  0.2723, -0.1006,  0.4388],\n",
       "          ...,\n",
       "          [-0.0758,  0.2001,  0.1977,  ...,  0.2723, -0.1006,  0.4388],\n",
       "          [-0.0758,  0.2001,  0.1977,  ...,  0.2723, -0.1006,  0.4388],\n",
       "          [-0.0758,  0.2001,  0.1977,  ...,  0.2723, -0.1006,  0.4388]],\n",
       " \n",
       "         [[-0.1909,  0.1320,  0.4030,  ...,  0.0346,  0.0614,  0.2956],\n",
       "          [-0.0966,  0.1920,  0.3414,  ..., -0.0144,  0.0038,  0.3242],\n",
       "          [-0.0255,  0.3182,  0.2620,  ...,  0.1954, -0.0039,  0.3855],\n",
       "          ...,\n",
       "          [-0.0758,  0.2001,  0.1977,  ...,  0.2723, -0.1006,  0.4388],\n",
       "          [-0.0758,  0.2001,  0.1977,  ...,  0.2723, -0.1006,  0.4388],\n",
       "          [-0.0758,  0.2001,  0.1977,  ...,  0.2723, -0.1006,  0.4388]],\n",
       " \n",
       "         [[-0.0584,  0.3065,  0.1580,  ...,  0.2317, -0.0934,  0.4788],\n",
       "          [-0.0758,  0.2001,  0.1977,  ...,  0.2723, -0.1006,  0.4388],\n",
       "          [ 0.0349,  0.3274,  0.3420,  ...,  0.0831, -0.1539,  0.4354],\n",
       "          ...,\n",
       "          [-0.0966,  0.1920,  0.3414,  ..., -0.0144,  0.0038,  0.3242],\n",
       "          [ 0.1322,  0.2379,  0.1948,  ...,  0.2159, -0.0966,  0.4424],\n",
       "          [ 0.0349,  0.3274,  0.3420,  ...,  0.0831, -0.1539,  0.4354]]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor([[[-0.1861, -0.1502, -0.2342,  ...,  0.2485,  0.1087,  0.3428],\n",
       "          [ 0.1379, -0.3111, -0.0206,  ...,  0.2527,  0.0966,  0.1609],\n",
       "          [-0.2473,  0.0715, -0.1432,  ..., -0.0138,  0.1214,  0.2440],\n",
       "          ...,\n",
       "          [-0.2473,  0.0715, -0.1432,  ..., -0.0138,  0.1214,  0.2440],\n",
       "          [-0.2473,  0.0715, -0.1432,  ..., -0.0138,  0.1214,  0.2440],\n",
       "          [-0.2473,  0.0715, -0.1432,  ..., -0.0138,  0.1214,  0.2440]],\n",
       " \n",
       "         [[ 0.1220, -0.3255, -0.0218,  ...,  0.0404, -0.1030,  0.1259],\n",
       "          [ 0.1379, -0.3111, -0.0206,  ...,  0.2527,  0.0966,  0.1609],\n",
       "          [ 0.0888, -0.1295, -0.3022,  ...,  0.1356, -0.1686,  0.0110],\n",
       "          ...,\n",
       "          [-0.2473,  0.0715, -0.1432,  ..., -0.0138,  0.1214,  0.2440],\n",
       "          [-0.2473,  0.0715, -0.1432,  ..., -0.0138,  0.1214,  0.2440],\n",
       "          [-0.2473,  0.0715, -0.1432,  ..., -0.0138,  0.1214,  0.2440]],\n",
       " \n",
       "         [[-0.2512, -0.0334, -0.2345,  ...,  0.0932,  0.1162, -0.0071],\n",
       "          [-0.2473,  0.0715, -0.1432,  ..., -0.0138,  0.1214,  0.2440],\n",
       "          [-0.0747, -0.0969, -0.3770,  ...,  0.0774, -0.0068,  0.1346],\n",
       "          ...,\n",
       "          [ 0.1379, -0.3111, -0.0206,  ...,  0.2527,  0.0966,  0.1609],\n",
       "          [-0.1169, -0.0789, -0.0709,  ...,  0.3369, -0.2297,  0.2160],\n",
       "          [-0.0747, -0.0969, -0.3770,  ...,  0.0774, -0.0068,  0.1346]]],\n",
       "        grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_sequences_onehot, torch.zeros(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2aa2e799-30c7-4c1d-ac02-a49c86735801",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "78299a23-0a33-4a1b-a2ad-2c13433609ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 29])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13df02a-9a30-4114-bad2-b4f654c80b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "    output, hidden = model(input_sequences_onehot, torch.zeros(12))\n",
    "    loss = loss_fn(output, target_sequences)\n",
    "    loss.backward() # Does backpropagation and calculates gradients\n",
    "    optimizer.step() # Updates the weights accordingly\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abf2076-866c-40bb-9b04-6035d4d6b229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
