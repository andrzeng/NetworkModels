{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0df2b066-6d8e-4a6a-bdac-14975399a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import random\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c8493e26-e3cc-4634-823d-d48fef2e4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim, qkv_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.qkv_dim = qkv_dim\n",
    "        \n",
    "        self.query_matrix = Parameter(torch.rand(embedding_dim, qkv_dim), requires_grad=True)\n",
    "        self.key_matrix = Parameter(torch.rand(embedding_dim, qkv_dim), requires_grad=True)\n",
    "        self.value_matrix = Parameter(torch.rand(embedding_dim, qkv_dim), requires_grad=True)\n",
    "        \n",
    "    def forward(self, embeddings):\n",
    "        queries = torch.matmul(embeddings, self.query_matrix)\n",
    "        keys = torch.matmul(embeddings, self.key_matrix)\n",
    "        values = torch.matmul(embeddings, self.value_matrix)\n",
    "\n",
    "        attention_scores = torch.matmul(queries, keys.T)\n",
    "        scaled_attention_scores = attention_scores/math.sqrt(self.qkv_dim)\n",
    "        softmaxed_attention_scores = torch.softmax(scaled_attention_scores, dim=1)\n",
    "        #print(softmaxed_attention_scores, values)\n",
    "        return torch.matmul(softmaxed_attention_scores, values)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e66f7082-421e-43ba-97c4-dc5db267f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim, qkv_dim, out_dim, n_heads=8):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.qkv_dim = qkv_dim\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        self.attention_heads = [SelfAttention(embedding_dim, qkv_dim) for i in range(n_heads)]\n",
    "        self.after_concat_multiplier_matrix = Parameter(torch.rand(qkv_dim*n_heads, out_dim), requires_grad=True)\n",
    "        \n",
    "    def forward(self, embeddings):\n",
    "        indiv_att_outs = [attention_head(embeddings) for attention_head in self.attention_heads]\n",
    "        concat_outs = torch.concat(indiv_att_outs,  dim=1)\n",
    "        recombined = torch.matmul(concat_outs, self.after_concat_multiplier_matrix)\n",
    "        \n",
    "        return recombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b48cf7-02bb-499f-9c20-96640420b72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFlayer(nn.Module)::\n",
    "    def __init__(self, attention_output_dim, out_dim):\n",
    "        pass\n",
    "        'todo'\n",
    "    \n",
    "    def forward(self, attention_outs):\n",
    "        pass\n",
    "        'todo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "da9d68be-b6bc-480d-aed1-c1aeb4566796",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = MultiheadAttention(5,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f5017f23-46f1-493c-a522-52f552e399d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 92.4192,  99.4669,  88.9275],\n",
       "        [ 93.7663, 100.2391,  89.8655],\n",
       "        [ 94.1293, 100.9355,  90.3312],\n",
       "        [ 94.1076, 100.9584,  90.3220]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73b3fdb1-e4e4-4f4d-89ae-f0076d3f2522",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, qkv_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c341bf-7f7a-4a9f-bf89-e4289f905c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367074bd-a6e5-4e9e-8560-cb8134fbffd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
